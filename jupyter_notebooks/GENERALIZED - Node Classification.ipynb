{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dgl.data import RedditDataset\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "from models import util_data, util_graph, util_model\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RedditDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features\n",
      "{'label': tensor([30, 17, 18,  ...,  3, 13, 13]), 'feat': tensor([[ 1.2334,  9.0430, -0.9233,  ..., -0.2579,  0.3112, -0.3772],\n",
      "        [-0.1386, -0.2022,  0.1277,  ...,  0.1563,  0.1048, -0.6534],\n",
      "        [-0.1330, -0.1962, -0.0296,  ...,  0.0358,  0.2864,  0.2744],\n",
      "        ...,\n",
      "        [-0.0614, -0.2022,  0.9698,  ...,  1.1064, -1.4323, -0.2398],\n",
      "        [-0.1606, -0.2022, -0.0892,  ...,  0.7440, -0.5046, -2.2288],\n",
      "        [ 0.0929,  0.2822,  0.1768,  ...,  0.2196,  0.5967,  0.5588]]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([ True, False,  True,  ..., False, False,  True]), 'train_mask': tensor([False,  True, False,  ...,  True,  True, False])}\n",
      "Edge features\n",
      "{}\n",
      "Edges\n",
      "(tensor([     0,      0,      0,  ..., 232920, 232931, 232952]), tensor([225202, 177307, 107546,  ..., 232897, 232907, 232910]))\n"
     ]
    }
   ],
   "source": [
    "# print(\"Number of categories:\", dataset.num_classes)\n",
    "print(\"Node features\")\n",
    "print(g.ndata)\n",
    "print(\"Edge features\")\n",
    "print(g.edata)\n",
    "print(\"Edges\")\n",
    "print(g.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume that we will be reading in the data from csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, Save the node and edge data to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data count: 232965\n"
     ]
    }
   ],
   "source": [
    "node_features = g.ndata['feat'].tolist()\n",
    "node_labels = g.ndata['label'].tolist()\n",
    "print(\"Data count:\", len(node_features))\n",
    "\n",
    "node_df = pd.DataFrame(node_features)\n",
    "node_df['node_ID'] = range(len(node_features))\n",
    "node_df['label'] = node_labels\n",
    "node_df.to_csv('../data/reddit_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_nodes = g.edges()[0].tolist()\n",
    "to_nodes = g.edges()[1].tolist()\n",
    "edge_df = pd.DataFrame()\n",
    "edge_df['from_node'] = from_nodes\n",
    "edge_df['to_node'] = to_nodes\n",
    "edge_df.to_csv('../data/reddit_edges.csv', index=True, index_label=\"edge_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read again from the csv files\n",
    "\n",
    "Reference: https://github.com/dglai/WWW20-Hands-on-Tutorial/blob/master/basic_tasks/1_load_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.read_csv(\"../data/reddit_nodes.csv\").set_index('node_ID')\n",
    "edge_df = pd.read_csv(\"../data/reddit_edges.csv\").set_index(\"edge_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "      <th>596</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "      <th>599</th>\n",
       "      <th>600</th>\n",
       "      <th>601</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.233415</td>\n",
       "      <td>9.043012</td>\n",
       "      <td>-0.923280</td>\n",
       "      <td>1.054183</td>\n",
       "      <td>-1.112501</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.042540</td>\n",
       "      <td>2.152007</td>\n",
       "      <td>-0.908296</td>\n",
       "      <td>0.713842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457901</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>-0.178169</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>-0.497469</td>\n",
       "      <td>-0.443911</td>\n",
       "      <td>-0.257895</td>\n",
       "      <td>0.311193</td>\n",
       "      <td>-0.377212</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.138552</td>\n",
       "      <td>-0.202219</td>\n",
       "      <td>0.127716</td>\n",
       "      <td>-0.418801</td>\n",
       "      <td>0.106761</td>\n",
       "      <td>0.302031</td>\n",
       "      <td>-0.936621</td>\n",
       "      <td>-0.980957</td>\n",
       "      <td>-0.098751</td>\n",
       "      <td>0.629780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238544</td>\n",
       "      <td>0.461295</td>\n",
       "      <td>0.114464</td>\n",
       "      <td>-0.408528</td>\n",
       "      <td>-0.331293</td>\n",
       "      <td>0.854006</td>\n",
       "      <td>0.156271</td>\n",
       "      <td>0.104781</td>\n",
       "      <td>-0.653420</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.133042</td>\n",
       "      <td>-0.196239</td>\n",
       "      <td>-0.029560</td>\n",
       "      <td>0.306849</td>\n",
       "      <td>0.073840</td>\n",
       "      <td>1.347005</td>\n",
       "      <td>0.695408</td>\n",
       "      <td>-0.657161</td>\n",
       "      <td>1.141495</td>\n",
       "      <td>-1.337327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989196</td>\n",
       "      <td>-1.283592</td>\n",
       "      <td>-1.252432</td>\n",
       "      <td>-1.707226</td>\n",
       "      <td>-0.860897</td>\n",
       "      <td>0.809932</td>\n",
       "      <td>0.035802</td>\n",
       "      <td>0.286367</td>\n",
       "      <td>0.274413</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.138552</td>\n",
       "      <td>-0.202219</td>\n",
       "      <td>0.183453</td>\n",
       "      <td>0.567036</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>-0.131731</td>\n",
       "      <td>-0.129563</td>\n",
       "      <td>0.387311</td>\n",
       "      <td>1.669948</td>\n",
       "      <td>0.048453</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.396239</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.204658</td>\n",
       "      <td>-0.495959</td>\n",
       "      <td>-0.329710</td>\n",
       "      <td>-0.363401</td>\n",
       "      <td>-0.440687</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.103306</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155081</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>-0.986740</td>\n",
       "      <td>1.667574</td>\n",
       "      <td>1.596521</td>\n",
       "      <td>-0.296647</td>\n",
       "      <td>-0.056293</td>\n",
       "      <td>0.792982</td>\n",
       "      <td>-0.782269</td>\n",
       "      <td>0.740889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517946</td>\n",
       "      <td>-0.264403</td>\n",
       "      <td>0.521236</td>\n",
       "      <td>1.056790</td>\n",
       "      <td>-0.498133</td>\n",
       "      <td>0.213124</td>\n",
       "      <td>-1.222432</td>\n",
       "      <td>-0.916983</td>\n",
       "      <td>0.488467</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "node_ID                                                                         \n",
       "0        1.233415  9.043012 -0.923280  1.054183 -1.112501 -0.020630  0.042540   \n",
       "1       -0.138552 -0.202219  0.127716 -0.418801  0.106761  0.302031 -0.936621   \n",
       "2       -0.133042 -0.196239 -0.029560  0.306849  0.073840  1.347005  0.695408   \n",
       "3       -0.138552 -0.202219  0.183453  0.567036  0.372372 -0.131731 -0.129563   \n",
       "4       -0.155081  0.013065 -0.986740  1.667574  1.596521 -0.296647 -0.056293   \n",
       "\n",
       "                7         8         9  ...       593       594       595  \\\n",
       "node_ID                                ...                                 \n",
       "0        2.152007 -0.908296  0.713842  ... -0.457901  0.002277 -0.178169   \n",
       "1       -0.980957 -0.098751  0.629780  ...  0.238544  0.461295  0.114464   \n",
       "2       -0.657161  1.141495 -1.337327  ...  0.989196 -1.283592 -1.252432   \n",
       "3        0.387311  1.669948  0.048453  ... -1.396239  0.010100  0.204658   \n",
       "4        0.792982 -0.782269  0.740889  ... -0.517946 -0.264403  0.521236   \n",
       "\n",
       "              596       597       598       599       600       601  label  \n",
       "node_ID                                                                     \n",
       "0        0.095668 -0.497469 -0.443911 -0.257895  0.311193 -0.377212     30  \n",
       "1       -0.408528 -0.331293  0.854006  0.156271  0.104781 -0.653420     17  \n",
       "2       -1.707226 -0.860897  0.809932  0.035802  0.286367  0.274413     18  \n",
       "3       -0.495959 -0.329710 -0.363401 -0.440687  0.006481  0.103306     23  \n",
       "4        1.056790 -0.498133  0.213124 -1.222432 -0.916983  0.488467     22  \n",
       "\n",
       "[5 rows x 603 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>225202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>177307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>107546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>176069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         from_node  to_node\n",
       "edge_ID                    \n",
       "0                0   225202\n",
       "1                0   177307\n",
       "2                0   107546\n",
       "3                0    15240\n",
       "4                0   176069"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = node_df[[col for col in node_df.columns if col != \"label\"]].values\n",
    "node_labels = node_df['label'].tolist() if 'label' in node_df.columns else None\n",
    "edge_features = edge_df[[col for col in edge_df.columns if col not in ['label', 'from_node', 'to_node']]].values\n",
    "edge_labels = edge_df['label'].tolist() if 'label' in edge_df.columns else None\n",
    "edge_src = edge_df['from_node'].to_numpy()\n",
    "edge_dst = edge_df['to_node'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23341453,  9.04301167, -0.92328006, ..., -0.25789541,\n",
       "         0.31119257, -0.37721241],\n",
       "       [-0.13855162, -0.20221879,  0.12771627, ...,  0.15627094,\n",
       "         0.10478096, -0.65342009],\n",
       "       [-0.13304172, -0.1962387 , -0.02956016, ...,  0.03580163,\n",
       "         0.28636733,  0.27441326],\n",
       "       ...,\n",
       "       [-0.06141297, -0.20221879,  0.96984237, ...,  1.10635602,\n",
       "        -1.43230617, -0.23978749],\n",
       "       [-0.16059124, -0.20221879, -0.08922971, ...,  0.74396491,\n",
       "        -0.50457329, -2.22882247],\n",
       "       [ 0.09286436,  0.2821691 ,  0.17679186, ...,  0.21959327,\n",
       "         0.59674859,  0.55883598]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn them into DGL graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=232965, num_edges=114615892,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "g = dgl.graph((edge_src, edge_dst))\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading features\n",
    "g.ndata['feat'] = torch.tensor(node_features)\n",
    "g.ndata['label'] = torch.tensor(node_labels)\n",
    "g.edata['feat'] = torch.tensor(edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=232965, num_edges=114615892,\n",
      "      ndata_schemes={'feat': Scheme(shape=(602,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(0,), dtype=torch.float64)})\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([     0,      0,      0,  ..., 232920, 232931, 232952]),\n",
       " tensor([225202, 177307, 107546,  ..., 232897, 232907, 232910]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying graph structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Nodes 232965\n",
      "# Edges 114615892\n",
      "Node 0 has 2204 degree\n",
      "Destinations from Node 0: tensor([225202, 177307, 107546,  ...,  55707,  18371,  72216])\n",
      "2204 nodes presucceed Node 0\n",
      "Node 0 has 2 in_edges and 2 out_edges\n",
      "Is this multigraph? False\n",
      "Does this graph has node 329? True\n",
      "Is there an edge between 329 and 324? False\n"
     ]
    }
   ],
   "source": [
    "print(\"# Nodes\", g.number_of_nodes())\n",
    "print(\"# Edges\", g.number_of_edges())\n",
    "print(\"Node 0 has {} degree\".format(g.in_degrees(0)))\n",
    "print(\"Destinations from Node 0:\", g.successors(0))\n",
    "print(\"{} nodes presucceed Node 0\".format(len(g.predecessors(0))))\n",
    "print(\"Node 0 has {} in_edges and {} out_edges\".format(len(g.in_edges(0)), len(g.out_edges(0))))\n",
    "print(\"Is this multigraph?\", g.is_multigraph)\n",
    "print(\"Does this graph has node 329?\", g.has_nodes(329))\n",
    "print(\"Is there an edge between 329 and 324?\", g.has_edges_between(329, 324))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-78db19ff38e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_undirected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkamada_kawai_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teemo/.local/lib/python3.6/site-packages/dgl/convert.py\u001b[0m in \u001b[0;36mto_networkx\u001b[0;34m(g, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDiGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m         \u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nx_g = g.to_networkx().to_undirected()\n",
    "pos = nx.kamada_kawai_layout(nx_g)\n",
    "nx.draw(nx_g, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Experiment Preprocessing (Data Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count in train:\t 139779\n",
      "Node count in val:\t 46593\n",
      "Node count in test:\t 46593\n",
      "Total Sum Check: True\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "node_count = len(node_features)\n",
    "\n",
    "split_index = np.zeros((node_count), dtype=np.int)\n",
    "split_index[:round(node_count * train_ratio)] = 1\n",
    "split_index[round(node_count*train_ratio): round(node_count*(train_ratio+val_ratio))] = 2\n",
    "split_index[round(node_count*(train_ratio+val_ratio)):] = 3\n",
    "\n",
    "np.random.shuffle(split_index)\n",
    "\n",
    "print(\"Node count in train:\\t\", sum(split_index == 1))\n",
    "print(\"Node count in val:\\t\", sum(split_index == 2))\n",
    "print(\"Node count in test:\\t\", sum(split_index == 3))\n",
    "print(\"Total Sum Check:\", sum(split_index == 1) + sum(split_index == 2) + sum(split_index == 3) == node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['train_mask'] = torch.tensor(split_index == 1)\n",
    "g.ndata['val_mask'] = torch.tensor(split_index == 2)\n",
    "g.ndata['test_mask'] = torch.tensor(split_index == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat': tensor([[ 1.2334,  9.0430, -0.9233,  ..., -0.2579,  0.3112, -0.3772],\n",
      "        [-0.1386, -0.2022,  0.1277,  ...,  0.1563,  0.1048, -0.6534],\n",
      "        [-0.1330, -0.1962, -0.0296,  ...,  0.0358,  0.2864,  0.2744],\n",
      "        ...,\n",
      "        [-0.0614, -0.2022,  0.9698,  ...,  1.1064, -1.4323, -0.2398],\n",
      "        [-0.1606, -0.2022, -0.0892,  ...,  0.7440, -0.5046, -2.2288],\n",
      "        [ 0.0929,  0.2822,  0.1768,  ...,  0.2196,  0.5967,  0.5588]],\n",
      "       dtype=torch.float64), 'train_mask': tensor([ True,  True,  True,  ..., False,  True, False]), 'val_mask': tensor([False, False, False,  ...,  True, False,  True]), 'test_mask': tensor([False, False, False,  ..., False, False, False]), 'label': tensor([30, 17, 18,  ...,  3, 13, 13])}\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1: GCN\n",
    "from dgl.nn import GraphConv\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, feat_dim, h_feat_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.num_layer = len(h_feat_dim)\n",
    "        self.h_feat_dim = h_feat_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.layers = []\n",
    "        prev_dim = feat_dim\n",
    "        for i in range(self.num_layer):\n",
    "            print(prev_dim)\n",
    "            print(h_feat_dim[i])\n",
    "            self.layers.append(GraphConv(prev_dim, h_feat_dim[i]))\n",
    "            prev_dim = h_feat_dim[i]\n",
    "        self.layers.append(GraphConv(prev_dim, num_classes))\n",
    "        \n",
    "    def forward(self, g, in_feat):\n",
    "        prev_feat = in_feat\n",
    "        for i in len(self.num_layer-1):\n",
    "            h = self.layers[i](g, prev_feat)\n",
    "            h = F.relu(h)\n",
    "            prev_feat = h\n",
    "        h = self.layers[-1](g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = len(node_features[0])\n",
    "num_classes = len(np.unique(node_labels))\n",
    "\n",
    "# THIS IS THE INPUTS FOR EXPERIMENTATION\n",
    "#Experimentation Scope\n",
    "\n",
    "model_types = ['GCN', 'GraphSAGE']\n",
    "aggregators = ['mean', 'max']\n",
    "h_feat_dim = [[32], [16], [8], [32, 16], [32, 8], [16, 4], [32, 16, 4]]\n",
    "activation_func = ['relu', 'sigmoid']\n",
    "loss_func = ['cross_entropy']\n",
    "optimization = ['adam', 'sgd']\n",
    "opt_learning_rate = [0.01, 0.1]\n",
    "train_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experimentation table\n",
    "tracking_values = []\n",
    "exp_ID_counter = 0\n",
    "for m in model_types:\n",
    "    for ag in aggregators:\n",
    "        for h in h_feat_dim:\n",
    "            for a in activation_func:\n",
    "                for l in loss_func:\n",
    "                    for opt in optimization:\n",
    "                        for opt_lr in opt_learning_rate:\n",
    "                            for i in range(train_iter):\n",
    "                                tracking_values.append([exp_ID_counter, i, m, ag, len(h), h, a, l, opt, opt_lr])\n",
    "                            exp_ID_counter += 1\n",
    "                            \n",
    "tracking_df = pd.DataFrame(tracking_values)\n",
    "tracking_df.columns = ['expID', 'iter', 'model', 'aggregator', 'num_layer', 'layer_dim', \n",
    "                        'activation_func', 'loss_func', 'optimization', 'opt_lr']\n",
    "\n",
    "performance_cols = ['loss', 'acc_train', 'avg_recall_train', 'avg_prec_train', 'avg_f1_train', \n",
    "                    'acc_val', 'avg_recall_val', 'avg_prec_val', 'avg_f1_val']\n",
    "\n",
    "for c in performance_cols:\n",
    "    tracking_df[c] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expID</th>\n",
       "      <th>iter</th>\n",
       "      <th>model</th>\n",
       "      <th>aggregator</th>\n",
       "      <th>num_layer</th>\n",
       "      <th>layer_dim</th>\n",
       "      <th>activation_func</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>optimization</th>\n",
       "      <th>opt_lr</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>avg_recall_train</th>\n",
       "      <th>avg_prec_train</th>\n",
       "      <th>avg_f1_train</th>\n",
       "      <th>acc_val</th>\n",
       "      <th>avg_recall_val</th>\n",
       "      <th>avg_prec_val</th>\n",
       "      <th>avg_f1_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCN</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>[32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GCN</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>[32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>GCN</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>[32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>GCN</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>[32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>GCN</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>[32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   expID  iter model aggregator  num_layer layer_dim activation_func  \\\n",
       "0      0     0   GCN       mean          1      [32]            relu   \n",
       "1      0     1   GCN       mean          1      [32]            relu   \n",
       "2      0     2   GCN       mean          1      [32]            relu   \n",
       "3      0     3   GCN       mean          1      [32]            relu   \n",
       "4      0     4   GCN       mean          1      [32]            relu   \n",
       "\n",
       "       loss_func optimization  opt_lr  loss acc_train avg_recall_train  \\\n",
       "0  cross_entropy         adam    0.01  None      None             None   \n",
       "1  cross_entropy         adam    0.01  None      None             None   \n",
       "2  cross_entropy         adam    0.01  None      None             None   \n",
       "3  cross_entropy         adam    0.01  None      None             None   \n",
       "4  cross_entropy         adam    0.01  None      None             None   \n",
       "\n",
       "  avg_prec_train avg_f1_train acc_val avg_recall_val avg_prec_val avg_f1_val  \n",
       "0           None         None    None           None         None       None  \n",
       "1           None         None    None           None         None       None  \n",
       "2           None         None    None           None         None       None  \n",
       "3           None         None    None           None         None       None  \n",
       "4           None         None    None           None         None       None  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, optimizer_type, learning_rate):\n",
    "    print(model.parameters())\n",
    "    if optimizer_type == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    elif optimizer_type == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    else:\n",
    "        print(optimizer_type, \"is currently not supported!\")\n",
    "        return None\n",
    "    return optimizer\n",
    "\n",
    "def run_node_clf_exp(g, train_iter, h_feat_dim, optimizer_type, opt_lr, loss_func):\n",
    "    model = GCN(g.ndata['feat'].shape[1], h_feat_dim, len(g.ndata['label'].unique()))\n",
    "    optimizer = get_optimizer(model, optimizer_type, opt_lr)\n",
    "    \n",
    "    best_train_acc = 0\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    \n",
    "    for e in range(train_iter):\n",
    "        logits = model(g, features)   # forward\n",
    "        pred = logits.argmax(1)       # compute prediction\n",
    "        \n",
    "        # TODO check the loss function type. Currently only cross entropy is supported\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[train_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[train_mask] == labels[test_mask]).float().mean()\n",
    "        \n",
    "        # Save the best validation accuracy\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            \n",
    "        # Backward prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if e%5 == 0:\n",
    "            print(\"In epoch {}, loss: {:.3f}, val acc: {:.3f}, test acc: {.3f} (best{:.3f})\".format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(3),\n",
       " tensor(4),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(7),\n",
       " tensor(8),\n",
       " tensor(9),\n",
       " tensor(10),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(29),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(32),\n",
       " tensor(33),\n",
       " tensor(34),\n",
       " tensor(35),\n",
       " tensor(36),\n",
       " tensor(37),\n",
       " tensor(38),\n",
       " tensor(39),\n",
       " tensor(40),\n",
       " tensor(41),\n",
       " tensor(42),\n",
       " tensor(43),\n",
       " tensor(44),\n",
       " tensor(45),\n",
       " tensor(46),\n",
       " tensor(47),\n",
       " tensor(48),\n",
       " tensor(49),\n",
       " tensor(50),\n",
       " tensor(51),\n",
       " tensor(52),\n",
       " tensor(53),\n",
       " tensor(54),\n",
       " tensor(55),\n",
       " tensor(56),\n",
       " tensor(57),\n",
       " tensor(58),\n",
       " tensor(59),\n",
       " tensor(60),\n",
       " tensor(61),\n",
       " tensor(62),\n",
       " tensor(63),\n",
       " tensor(64),\n",
       " tensor(65),\n",
       " tensor(66),\n",
       " tensor(67),\n",
       " tensor(68),\n",
       " tensor(69),\n",
       " tensor(70),\n",
       " tensor(71),\n",
       " tensor(72),\n",
       " tensor(73),\n",
       " tensor(74),\n",
       " tensor(75),\n",
       " tensor(76),\n",
       " tensor(77),\n",
       " tensor(78),\n",
       " tensor(79),\n",
       " tensor(80),\n",
       " tensor(81),\n",
       " tensor(82),\n",
       " tensor(83),\n",
       " tensor(84),\n",
       " tensor(85),\n",
       " tensor(86),\n",
       " tensor(87),\n",
       " tensor(88),\n",
       " tensor(89),\n",
       " tensor(90),\n",
       " tensor(91),\n",
       " tensor(92),\n",
       " tensor(93),\n",
       " tensor(94),\n",
       " tensor(95),\n",
       " tensor(96),\n",
       " tensor(97),\n",
       " tensor(98),\n",
       " tensor(99),\n",
       " tensor(100),\n",
       " tensor(101),\n",
       " tensor(102),\n",
       " tensor(103),\n",
       " tensor(104),\n",
       " tensor(105),\n",
       " tensor(106),\n",
       " tensor(107),\n",
       " tensor(108),\n",
       " tensor(109),\n",
       " tensor(110),\n",
       " tensor(111),\n",
       " tensor(112),\n",
       " tensor(113),\n",
       " tensor(114),\n",
       " tensor(115),\n",
       " tensor(116),\n",
       " tensor(117),\n",
       " tensor(118),\n",
       " tensor(119),\n",
       " tensor(120),\n",
       " tensor(121),\n",
       " tensor(122),\n",
       " tensor(123),\n",
       " tensor(124),\n",
       " tensor(125),\n",
       " tensor(126),\n",
       " tensor(127),\n",
       " tensor(128),\n",
       " tensor(129),\n",
       " tensor(130),\n",
       " tensor(131),\n",
       " tensor(132),\n",
       " tensor(133),\n",
       " tensor(134),\n",
       " tensor(135),\n",
       " tensor(136),\n",
       " tensor(137),\n",
       " tensor(138),\n",
       " tensor(139),\n",
       " tensor(140),\n",
       " tensor(141),\n",
       " tensor(142),\n",
       " tensor(143),\n",
       " tensor(144),\n",
       " tensor(145),\n",
       " tensor(146),\n",
       " tensor(147),\n",
       " tensor(148),\n",
       " tensor(149),\n",
       " tensor(150),\n",
       " tensor(151),\n",
       " tensor(152),\n",
       " tensor(153),\n",
       " tensor(154),\n",
       " tensor(155),\n",
       " tensor(156),\n",
       " tensor(157),\n",
       " tensor(158),\n",
       " tensor(159),\n",
       " tensor(160),\n",
       " tensor(161),\n",
       " tensor(162),\n",
       " tensor(163),\n",
       " tensor(164),\n",
       " tensor(165),\n",
       " tensor(166),\n",
       " tensor(167),\n",
       " tensor(168),\n",
       " tensor(169),\n",
       " tensor(170),\n",
       " tensor(171),\n",
       " tensor(172),\n",
       " tensor(173),\n",
       " tensor(174),\n",
       " tensor(175),\n",
       " tensor(176),\n",
       " tensor(177),\n",
       " tensor(178),\n",
       " tensor(179),\n",
       " tensor(180),\n",
       " tensor(181),\n",
       " tensor(182),\n",
       " tensor(183),\n",
       " tensor(184),\n",
       " tensor(185),\n",
       " tensor(186),\n",
       " tensor(187),\n",
       " tensor(188),\n",
       " tensor(189),\n",
       " tensor(190),\n",
       " tensor(191),\n",
       " tensor(192),\n",
       " tensor(193),\n",
       " tensor(194),\n",
       " tensor(195),\n",
       " tensor(196),\n",
       " tensor(197),\n",
       " tensor(198),\n",
       " tensor(199),\n",
       " tensor(200),\n",
       " tensor(201),\n",
       " tensor(202),\n",
       " tensor(203),\n",
       " tensor(204),\n",
       " tensor(205),\n",
       " tensor(206),\n",
       " tensor(207),\n",
       " tensor(208),\n",
       " tensor(209),\n",
       " tensor(210),\n",
       " tensor(211),\n",
       " tensor(212),\n",
       " tensor(213),\n",
       " tensor(214),\n",
       " tensor(215),\n",
       " tensor(216),\n",
       " tensor(217),\n",
       " tensor(218),\n",
       " tensor(219),\n",
       " tensor(220),\n",
       " tensor(221),\n",
       " tensor(222),\n",
       " tensor(223),\n",
       " tensor(224),\n",
       " tensor(225),\n",
       " tensor(226),\n",
       " tensor(227),\n",
       " tensor(228),\n",
       " tensor(229),\n",
       " tensor(230),\n",
       " tensor(231),\n",
       " tensor(232),\n",
       " tensor(233),\n",
       " tensor(234),\n",
       " tensor(235),\n",
       " tensor(236),\n",
       " tensor(237),\n",
       " tensor(238),\n",
       " tensor(239),\n",
       " tensor(240),\n",
       " tensor(241),\n",
       " tensor(242),\n",
       " tensor(243),\n",
       " tensor(244),\n",
       " tensor(245),\n",
       " tensor(246),\n",
       " tensor(247),\n",
       " tensor(248),\n",
       " tensor(249),\n",
       " tensor(250),\n",
       " tensor(251),\n",
       " tensor(252),\n",
       " tensor(253),\n",
       " tensor(254),\n",
       " tensor(255),\n",
       " tensor(256),\n",
       " tensor(257),\n",
       " tensor(258),\n",
       " tensor(259),\n",
       " tensor(260),\n",
       " tensor(261),\n",
       " tensor(262),\n",
       " tensor(263),\n",
       " tensor(264),\n",
       " tensor(265),\n",
       " tensor(266),\n",
       " tensor(267),\n",
       " tensor(268),\n",
       " tensor(269),\n",
       " tensor(270),\n",
       " tensor(271),\n",
       " tensor(272),\n",
       " tensor(273),\n",
       " tensor(274),\n",
       " tensor(275),\n",
       " tensor(276),\n",
       " tensor(277),\n",
       " tensor(278),\n",
       " tensor(279),\n",
       " tensor(280),\n",
       " tensor(281),\n",
       " tensor(282),\n",
       " tensor(283),\n",
       " tensor(284),\n",
       " tensor(285),\n",
       " tensor(286),\n",
       " tensor(287),\n",
       " tensor(288),\n",
       " tensor(289),\n",
       " tensor(290),\n",
       " tensor(291),\n",
       " tensor(292),\n",
       " tensor(293),\n",
       " tensor(294),\n",
       " tensor(295),\n",
       " tensor(296),\n",
       " tensor(297),\n",
       " tensor(298),\n",
       " tensor(299),\n",
       " tensor(300),\n",
       " tensor(301),\n",
       " tensor(302),\n",
       " tensor(303),\n",
       " tensor(304),\n",
       " tensor(305),\n",
       " tensor(306),\n",
       " tensor(307),\n",
       " tensor(308),\n",
       " tensor(309),\n",
       " tensor(310),\n",
       " tensor(311),\n",
       " tensor(312),\n",
       " tensor(313),\n",
       " tensor(314),\n",
       " tensor(315),\n",
       " tensor(316),\n",
       " tensor(317),\n",
       " tensor(318),\n",
       " tensor(319),\n",
       " tensor(320),\n",
       " tensor(321),\n",
       " tensor(322),\n",
       " tensor(323),\n",
       " tensor(324),\n",
       " tensor(325),\n",
       " tensor(326),\n",
       " tensor(327),\n",
       " tensor(328),\n",
       " tensor(329),\n",
       " tensor(330),\n",
       " tensor(331),\n",
       " tensor(332),\n",
       " tensor(333),\n",
       " tensor(334),\n",
       " tensor(335),\n",
       " tensor(336),\n",
       " tensor(337),\n",
       " tensor(338),\n",
       " tensor(339),\n",
       " tensor(340),\n",
       " tensor(341),\n",
       " tensor(342),\n",
       " tensor(343),\n",
       " tensor(344),\n",
       " tensor(345),\n",
       " tensor(346),\n",
       " tensor(347),\n",
       " tensor(348),\n",
       " tensor(349),\n",
       " tensor(350),\n",
       " tensor(351),\n",
       " tensor(352),\n",
       " tensor(353),\n",
       " tensor(354),\n",
       " tensor(355),\n",
       " tensor(356),\n",
       " tensor(357),\n",
       " tensor(358),\n",
       " tensor(359),\n",
       " tensor(360),\n",
       " tensor(361),\n",
       " tensor(362),\n",
       " tensor(363),\n",
       " tensor(364),\n",
       " tensor(365),\n",
       " tensor(366),\n",
       " tensor(367),\n",
       " tensor(368),\n",
       " tensor(369),\n",
       " tensor(370),\n",
       " tensor(371),\n",
       " tensor(372),\n",
       " tensor(373),\n",
       " tensor(374),\n",
       " tensor(375),\n",
       " tensor(376),\n",
       " tensor(377),\n",
       " tensor(378),\n",
       " tensor(379),\n",
       " tensor(380),\n",
       " tensor(381),\n",
       " tensor(382),\n",
       " tensor(383),\n",
       " tensor(384),\n",
       " tensor(385),\n",
       " tensor(386),\n",
       " tensor(387),\n",
       " tensor(388),\n",
       " tensor(389),\n",
       " tensor(390),\n",
       " tensor(391),\n",
       " tensor(392),\n",
       " tensor(393),\n",
       " tensor(394),\n",
       " tensor(395),\n",
       " tensor(396),\n",
       " tensor(397),\n",
       " tensor(398),\n",
       " tensor(399),\n",
       " tensor(400),\n",
       " tensor(401),\n",
       " tensor(402),\n",
       " tensor(403),\n",
       " tensor(404),\n",
       " tensor(405),\n",
       " tensor(406),\n",
       " tensor(407),\n",
       " tensor(408),\n",
       " tensor(409),\n",
       " tensor(410),\n",
       " tensor(411),\n",
       " tensor(412),\n",
       " tensor(413),\n",
       " tensor(414),\n",
       " tensor(415),\n",
       " tensor(416),\n",
       " tensor(417),\n",
       " tensor(418),\n",
       " tensor(419),\n",
       " tensor(420),\n",
       " tensor(421),\n",
       " tensor(422),\n",
       " tensor(423),\n",
       " tensor(424),\n",
       " tensor(425),\n",
       " tensor(426),\n",
       " tensor(427),\n",
       " tensor(428),\n",
       " tensor(429),\n",
       " tensor(430),\n",
       " tensor(431),\n",
       " tensor(432),\n",
       " tensor(433),\n",
       " tensor(434),\n",
       " tensor(435),\n",
       " tensor(436),\n",
       " tensor(437),\n",
       " tensor(438),\n",
       " tensor(439),\n",
       " tensor(440),\n",
       " tensor(441),\n",
       " tensor(442),\n",
       " tensor(443),\n",
       " tensor(444),\n",
       " tensor(445),\n",
       " tensor(446),\n",
       " tensor(447),\n",
       " tensor(448),\n",
       " tensor(449),\n",
       " tensor(450),\n",
       " tensor(451),\n",
       " tensor(452),\n",
       " tensor(453),\n",
       " tensor(454),\n",
       " tensor(455),\n",
       " tensor(456),\n",
       " tensor(457),\n",
       " tensor(458),\n",
       " tensor(459),\n",
       " tensor(460),\n",
       " tensor(461),\n",
       " tensor(462),\n",
       " tensor(463),\n",
       " tensor(464),\n",
       " tensor(465),\n",
       " tensor(466),\n",
       " tensor(467),\n",
       " tensor(468),\n",
       " tensor(469),\n",
       " tensor(470),\n",
       " tensor(471),\n",
       " tensor(472),\n",
       " tensor(473),\n",
       " tensor(474),\n",
       " tensor(475),\n",
       " tensor(476),\n",
       " tensor(477),\n",
       " tensor(478),\n",
       " tensor(479),\n",
       " tensor(480),\n",
       " tensor(481),\n",
       " tensor(482),\n",
       " tensor(483),\n",
       " tensor(484),\n",
       " tensor(485),\n",
       " tensor(486),\n",
       " tensor(487),\n",
       " tensor(488),\n",
       " tensor(489),\n",
       " tensor(490),\n",
       " tensor(491),\n",
       " tensor(492),\n",
       " tensor(493),\n",
       " tensor(494),\n",
       " tensor(495),\n",
       " tensor(496),\n",
       " tensor(497),\n",
       " tensor(498),\n",
       " tensor(499),\n",
       " tensor(500),\n",
       " tensor(501),\n",
       " tensor(502),\n",
       " tensor(503),\n",
       " tensor(504),\n",
       " tensor(505),\n",
       " tensor(506),\n",
       " tensor(507),\n",
       " tensor(508),\n",
       " tensor(509),\n",
       " tensor(510),\n",
       " tensor(511),\n",
       " tensor(512),\n",
       " tensor(513),\n",
       " tensor(514),\n",
       " tensor(515),\n",
       " tensor(516),\n",
       " tensor(517),\n",
       " tensor(518),\n",
       " tensor(519),\n",
       " tensor(520),\n",
       " tensor(521),\n",
       " tensor(522),\n",
       " tensor(523),\n",
       " tensor(524),\n",
       " tensor(525),\n",
       " tensor(526),\n",
       " tensor(527),\n",
       " tensor(528),\n",
       " tensor(529),\n",
       " tensor(530),\n",
       " tensor(531),\n",
       " tensor(532),\n",
       " tensor(533),\n",
       " tensor(534),\n",
       " tensor(535),\n",
       " tensor(536),\n",
       " tensor(537),\n",
       " tensor(538),\n",
       " tensor(539),\n",
       " tensor(540),\n",
       " tensor(541),\n",
       " tensor(542),\n",
       " tensor(543),\n",
       " tensor(544),\n",
       " tensor(545),\n",
       " tensor(546),\n",
       " tensor(547),\n",
       " tensor(548),\n",
       " tensor(549),\n",
       " tensor(550),\n",
       " tensor(551),\n",
       " tensor(552),\n",
       " tensor(553),\n",
       " tensor(554),\n",
       " tensor(555),\n",
       " tensor(556),\n",
       " tensor(557),\n",
       " tensor(558),\n",
       " tensor(559),\n",
       " tensor(560),\n",
       " tensor(561),\n",
       " tensor(562),\n",
       " tensor(563),\n",
       " tensor(564),\n",
       " tensor(565),\n",
       " tensor(566),\n",
       " tensor(567),\n",
       " tensor(568),\n",
       " tensor(569),\n",
       " tensor(570),\n",
       " tensor(571),\n",
       " tensor(572),\n",
       " tensor(573),\n",
       " tensor(574),\n",
       " tensor(575),\n",
       " tensor(576),\n",
       " tensor(577),\n",
       " tensor(578),\n",
       " tensor(579),\n",
       " tensor(580),\n",
       " tensor(581),\n",
       " tensor(582),\n",
       " tensor(583),\n",
       " tensor(584),\n",
       " tensor(585),\n",
       " tensor(586),\n",
       " tensor(587),\n",
       " tensor(588),\n",
       " tensor(589),\n",
       " tensor(590),\n",
       " tensor(591),\n",
       " tensor(592),\n",
       " tensor(593),\n",
       " tensor(594),\n",
       " tensor(595),\n",
       " tensor(596),\n",
       " tensor(597),\n",
       " tensor(598),\n",
       " tensor(599),\n",
       " tensor(600),\n",
       " tensor(601),\n",
       " tensor(602),\n",
       " tensor(603),\n",
       " tensor(604),\n",
       " tensor(605),\n",
       " tensor(606),\n",
       " tensor(607),\n",
       " tensor(608),\n",
       " tensor(609),\n",
       " tensor(610),\n",
       " tensor(611),\n",
       " tensor(612),\n",
       " tensor(613),\n",
       " tensor(614),\n",
       " tensor(615),\n",
       " tensor(616),\n",
       " tensor(617),\n",
       " tensor(618),\n",
       " tensor(619),\n",
       " tensor(620),\n",
       " tensor(621),\n",
       " tensor(622),\n",
       " tensor(623),\n",
       " tensor(624),\n",
       " tensor(625),\n",
       " tensor(626),\n",
       " tensor(627),\n",
       " tensor(628),\n",
       " tensor(629),\n",
       " tensor(630),\n",
       " tensor(631),\n",
       " tensor(632),\n",
       " tensor(633),\n",
       " tensor(634),\n",
       " tensor(635),\n",
       " tensor(636),\n",
       " tensor(637),\n",
       " tensor(638),\n",
       " tensor(639),\n",
       " tensor(640),\n",
       " tensor(641),\n",
       " tensor(642),\n",
       " tensor(643),\n",
       " tensor(644),\n",
       " tensor(645),\n",
       " tensor(646),\n",
       " tensor(647),\n",
       " tensor(648),\n",
       " tensor(649),\n",
       " tensor(650),\n",
       " tensor(651),\n",
       " tensor(652),\n",
       " tensor(653),\n",
       " tensor(654),\n",
       " tensor(655),\n",
       " tensor(656),\n",
       " tensor(657),\n",
       " tensor(658),\n",
       " tensor(659),\n",
       " tensor(660),\n",
       " tensor(661),\n",
       " tensor(662),\n",
       " tensor(663),\n",
       " tensor(664),\n",
       " tensor(665),\n",
       " tensor(666),\n",
       " tensor(667),\n",
       " tensor(668),\n",
       " tensor(669),\n",
       " tensor(670),\n",
       " tensor(671),\n",
       " tensor(672),\n",
       " tensor(673),\n",
       " tensor(674),\n",
       " tensor(675),\n",
       " tensor(676),\n",
       " tensor(677),\n",
       " tensor(678),\n",
       " tensor(679),\n",
       " tensor(680),\n",
       " tensor(681),\n",
       " tensor(682),\n",
       " tensor(683),\n",
       " tensor(684),\n",
       " tensor(685),\n",
       " tensor(686),\n",
       " tensor(687),\n",
       " tensor(688),\n",
       " tensor(689),\n",
       " tensor(690),\n",
       " tensor(691),\n",
       " tensor(692),\n",
       " tensor(693),\n",
       " tensor(694),\n",
       " tensor(695),\n",
       " tensor(696),\n",
       " tensor(697),\n",
       " tensor(698),\n",
       " tensor(699),\n",
       " tensor(700),\n",
       " tensor(701),\n",
       " tensor(702),\n",
       " tensor(703),\n",
       " tensor(704),\n",
       " tensor(705),\n",
       " tensor(706),\n",
       " tensor(707),\n",
       " tensor(708),\n",
       " tensor(709),\n",
       " tensor(710),\n",
       " tensor(711),\n",
       " tensor(712),\n",
       " tensor(713),\n",
       " tensor(714),\n",
       " tensor(715),\n",
       " tensor(716),\n",
       " tensor(717),\n",
       " tensor(718),\n",
       " tensor(719),\n",
       " tensor(720),\n",
       " tensor(721),\n",
       " tensor(722),\n",
       " tensor(723),\n",
       " tensor(724),\n",
       " tensor(725),\n",
       " tensor(726),\n",
       " tensor(727),\n",
       " tensor(728),\n",
       " tensor(729),\n",
       " tensor(730),\n",
       " tensor(731),\n",
       " tensor(732),\n",
       " tensor(733),\n",
       " tensor(734),\n",
       " tensor(735),\n",
       " tensor(736),\n",
       " tensor(737),\n",
       " tensor(738),\n",
       " tensor(739),\n",
       " tensor(740),\n",
       " tensor(741),\n",
       " tensor(742),\n",
       " tensor(743),\n",
       " tensor(744),\n",
       " tensor(745),\n",
       " tensor(746),\n",
       " tensor(747),\n",
       " tensor(748),\n",
       " tensor(749),\n",
       " tensor(750),\n",
       " tensor(751),\n",
       " tensor(752),\n",
       " tensor(753),\n",
       " tensor(754),\n",
       " tensor(755),\n",
       " tensor(756),\n",
       " tensor(757),\n",
       " tensor(758),\n",
       " tensor(759),\n",
       " tensor(760),\n",
       " tensor(761),\n",
       " tensor(762),\n",
       " tensor(763),\n",
       " tensor(764),\n",
       " tensor(765),\n",
       " tensor(766),\n",
       " tensor(767),\n",
       " tensor(768),\n",
       " tensor(769),\n",
       " tensor(770),\n",
       " tensor(771),\n",
       " tensor(772),\n",
       " tensor(773),\n",
       " tensor(774),\n",
       " tensor(775),\n",
       " tensor(776),\n",
       " tensor(777),\n",
       " tensor(778),\n",
       " tensor(779),\n",
       " tensor(780),\n",
       " tensor(781),\n",
       " tensor(782),\n",
       " tensor(783),\n",
       " tensor(784),\n",
       " tensor(785),\n",
       " tensor(786),\n",
       " tensor(787),\n",
       " tensor(788),\n",
       " tensor(789),\n",
       " tensor(790),\n",
       " tensor(791),\n",
       " tensor(792),\n",
       " tensor(793),\n",
       " tensor(794),\n",
       " tensor(795),\n",
       " tensor(796),\n",
       " tensor(797),\n",
       " tensor(798),\n",
       " tensor(799),\n",
       " tensor(800),\n",
       " tensor(801),\n",
       " tensor(802),\n",
       " tensor(803),\n",
       " tensor(804),\n",
       " tensor(805),\n",
       " tensor(806),\n",
       " tensor(807),\n",
       " tensor(808),\n",
       " tensor(809),\n",
       " tensor(810),\n",
       " tensor(811),\n",
       " tensor(812),\n",
       " tensor(813),\n",
       " tensor(814),\n",
       " tensor(815),\n",
       " tensor(816),\n",
       " tensor(817),\n",
       " tensor(818),\n",
       " tensor(819),\n",
       " tensor(820),\n",
       " tensor(821),\n",
       " tensor(822),\n",
       " tensor(823),\n",
       " tensor(824),\n",
       " tensor(825),\n",
       " tensor(826),\n",
       " tensor(827),\n",
       " tensor(828),\n",
       " tensor(829),\n",
       " tensor(830),\n",
       " tensor(831),\n",
       " tensor(832),\n",
       " tensor(833),\n",
       " tensor(834),\n",
       " tensor(835),\n",
       " tensor(836),\n",
       " tensor(837),\n",
       " tensor(838),\n",
       " tensor(839),\n",
       " tensor(840),\n",
       " tensor(841),\n",
       " tensor(842),\n",
       " tensor(843),\n",
       " tensor(844),\n",
       " tensor(845),\n",
       " tensor(846),\n",
       " tensor(847),\n",
       " tensor(848),\n",
       " tensor(849),\n",
       " tensor(850),\n",
       " tensor(851),\n",
       " tensor(852),\n",
       " tensor(853),\n",
       " tensor(854),\n",
       " tensor(855),\n",
       " tensor(856),\n",
       " tensor(857),\n",
       " tensor(858),\n",
       " tensor(859),\n",
       " tensor(860),\n",
       " tensor(861),\n",
       " tensor(862),\n",
       " tensor(863),\n",
       " tensor(864),\n",
       " tensor(865),\n",
       " tensor(866),\n",
       " tensor(867),\n",
       " tensor(868),\n",
       " tensor(869),\n",
       " tensor(870),\n",
       " tensor(871),\n",
       " tensor(872),\n",
       " tensor(873),\n",
       " tensor(874),\n",
       " tensor(875),\n",
       " tensor(876),\n",
       " tensor(877),\n",
       " tensor(878),\n",
       " tensor(879),\n",
       " tensor(880),\n",
       " tensor(881),\n",
       " tensor(882),\n",
       " tensor(883),\n",
       " tensor(884),\n",
       " tensor(885),\n",
       " tensor(886),\n",
       " tensor(887),\n",
       " tensor(888),\n",
       " tensor(889),\n",
       " tensor(890),\n",
       " tensor(891),\n",
       " tensor(892),\n",
       " tensor(893),\n",
       " tensor(894),\n",
       " tensor(895),\n",
       " tensor(896),\n",
       " tensor(897),\n",
       " tensor(898),\n",
       " tensor(899),\n",
       " tensor(900),\n",
       " tensor(901),\n",
       " tensor(902),\n",
       " tensor(903),\n",
       " tensor(904),\n",
       " tensor(905),\n",
       " tensor(906),\n",
       " tensor(907),\n",
       " tensor(908),\n",
       " tensor(909),\n",
       " tensor(910),\n",
       " tensor(911),\n",
       " tensor(912),\n",
       " tensor(913),\n",
       " tensor(914),\n",
       " tensor(915),\n",
       " tensor(916),\n",
       " tensor(917),\n",
       " tensor(918),\n",
       " tensor(919),\n",
       " tensor(920),\n",
       " tensor(921),\n",
       " tensor(922),\n",
       " tensor(923),\n",
       " tensor(924),\n",
       " tensor(925),\n",
       " tensor(926),\n",
       " tensor(927),\n",
       " tensor(928),\n",
       " tensor(929),\n",
       " tensor(930),\n",
       " tensor(931),\n",
       " tensor(932),\n",
       " tensor(933),\n",
       " tensor(934),\n",
       " tensor(935),\n",
       " tensor(936),\n",
       " tensor(937),\n",
       " tensor(938),\n",
       " tensor(939),\n",
       " tensor(940),\n",
       " tensor(941),\n",
       " tensor(942),\n",
       " tensor(943),\n",
       " tensor(944),\n",
       " tensor(945),\n",
       " tensor(946),\n",
       " tensor(947),\n",
       " tensor(948),\n",
       " tensor(949),\n",
       " tensor(950),\n",
       " tensor(951),\n",
       " tensor(952),\n",
       " tensor(953),\n",
       " tensor(954),\n",
       " tensor(955),\n",
       " tensor(956),\n",
       " tensor(957),\n",
       " tensor(958),\n",
       " tensor(959),\n",
       " tensor(960),\n",
       " tensor(961),\n",
       " tensor(962),\n",
       " tensor(963),\n",
       " tensor(964),\n",
       " tensor(965),\n",
       " tensor(966),\n",
       " tensor(967),\n",
       " tensor(968),\n",
       " tensor(969),\n",
       " tensor(970),\n",
       " tensor(971),\n",
       " tensor(972),\n",
       " tensor(973),\n",
       " tensor(974),\n",
       " tensor(975),\n",
       " tensor(976),\n",
       " tensor(977),\n",
       " tensor(978),\n",
       " tensor(979),\n",
       " tensor(980),\n",
       " tensor(981),\n",
       " tensor(982),\n",
       " tensor(983),\n",
       " tensor(984),\n",
       " tensor(985),\n",
       " tensor(986),\n",
       " tensor(987),\n",
       " tensor(988),\n",
       " tensor(989),\n",
       " tensor(990),\n",
       " tensor(991),\n",
       " tensor(992),\n",
       " tensor(993),\n",
       " tensor(994),\n",
       " tensor(995),\n",
       " tensor(996),\n",
       " tensor(997),\n",
       " tensor(998),\n",
       " tensor(999),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "model = GCN(g.ndata['feat'].shape[1], [32], len(g.ndata['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fcc3d748258>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-9e40a36b4cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/teemo/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     46\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     47\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teemo/.local/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN mean [32] relu cross_entropy adam 0.01\n",
      "602\n",
      "32\n",
      "<generator object Module.parameters at 0x7fcc3d7481a8>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-e709c662dd15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mrun_node_clf_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-026c75a9d067>\u001b[0m in \u001b[0;36mrun_node_clf_exp\u001b[0;34m(g, train_iter, h_feat_dim, optimizer_type, opt_lr, loss_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_node_clf_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_feat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_feat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbest_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-026c75a9d067>\u001b[0m in \u001b[0;36mget_optimizer\u001b[0;34m(model, optimizer_type, learning_rate)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moptimizer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teemo/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     46\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     47\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teemo/.local/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "for ind, row in tracking_df.iterrows():\n",
    "    m = row['model']\n",
    "    ag = row['aggregator']\n",
    "    h = row['layer_dim']\n",
    "    a = row['activation_func']\n",
    "    l = row['loss_func']\n",
    "    opt = row['optimization']\n",
    "    lr = row['opt_lr']\n",
    "    \n",
    "    print(m, ag, h, a, l, opt, lr)\n",
    "    \n",
    "    run_node_clf_exp(g, 10, h, opt, lr, l)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "optimizer = torch.optim.Adam(model.parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
